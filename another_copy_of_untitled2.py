# -*- coding: utf-8 -*-
"""Another copy of Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10SFIetZa1jvcsv_5K4dDKfvfTtSU7tSh
"""

import numpy as np
import pandas as pd
import seaborn as sns

df = pd.read_csv("/EXCEL DATA.csv")

df.shape

df.dtypes

df.isna().sum()

df.isnull().values.any()

df.describe()

df["Attrition"].value_counts()

sns.countplot(df["Attrition"])

(1233-237)/1233

import matplotlib.pyplot as plt
plt.subplots (figsize=(12,4))
sns.countplot(x='Age',hue='Attrition',data=df,palette='colorblind')

for column in df.columns:
  if df[column].dtype == object:
    print(str(column)+':'+ str(df[column].unique()))
    print(df[column].value_counts())
    print('_')

plt.figure(figsize=(14,14))
sns.heatmap(df.corr(), annot=True,fmt = '.0%')

from sklearn.preprocessing import LabelEncoder

for column in df.columns:
    if df[column].dtype == np.number:
        continue
    df[column] = LabelEncoder().fit_transform(df[column])

df['Age_Years'] = df['Age']

df

X = df.iloc[:, 1:df.shape[1]].values
Y = df.iloc[:, 0].values

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25,random_state=0)

from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 10 , criterion = 'entropy',random_state = 0)
forest.fit(X_train,Y_train)

forest.score(X_train, Y_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test, forest.predict(X_test))
TN = cm[0][0]
TP = cm[1][1]
FN = cm[1][0]
FP = cm[0][1]
print(cm)
print('Model Testing Accuracy = {}'.format((TP + TN) / (TP + TN + FN + FP)))

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
clf = tree.DecisionTreeClassifier()

clf=clf.fit(X,Y)

y_pred = clf.predict(X_test)
from sklearn.metrics import *
print("acuuracy : ",accuracy_score(y_pred,Y_test)*100)
print(classification_report(y_pred,Y_test))

df = pd.get_dummies(df, columns=['Attrition'], drop_first=True)
df.head()

df = pd.get_dummies(df, columns=['OverTime'], drop_first=True)
df.head()

type(df.Attrition_1)

df['Attrition_1'] = df['Attrition_1'].astype(int)

df['OverTime_1'] = df['OverTime_1'].astype(int)

features = df[[ 'DistanceFromHome','Gender', 'MonthlyIncome', 'JobRole', 'PerformanceRating', 'TotalWorkingYears','YearsAtCompany','NumCompaniesWorked'] ]
target = df['Attrition_1']

features

target

features.shape

features.columns

features.info()

acc = []
model =[]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(features,target,test_size = 0.25,random_state=2)

from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 10 , criterion = 'entropy',random_state = 0)
forest.fit(X_train,y_train)

forest.score(X_train, Y_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, forest.predict(X_test))
TN = cm[0][0]
TP = cm[1][1]
FN = cm[1][0]
FP = cm[0][1]
print(cm)
print('Model Testing Accuracy = {}'.format((TP + TN) / (TP + TN + FN + FP)))

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
clf = tree.DecisionTreeClassifier()

clf = clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)
from sklearn.metrics import *
print("acuuracy : ",accuracy_score(y_pred,y_test)*100)
print(classification_report(y_pred,y_test))

from sklearn.naive_bayes import GaussianNB


model = GaussianNB()


model.fit(X_train,y_train)

from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    ConfusionMatrixDisplay,
    f1_score,
)

y_pred = model.predict(X_test)
accuray = accuracy_score(y_pred, y_test)
f1 = f1_score(y_pred, y_test, average="weighted")

print("Accuracy:", accuray)
print("F1 Score:",f1)

from sklearn.svm import SVC
clf = SVC(kernel='linear')


clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)
from sklearn.metrics import *
print("acuuracy : ",accuracy_score(y_pred,y_test)*100)
print(classification_report(y_pred,y_test))

from sklearn.linear_model import LogisticRegression

classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train,y_train)

from sklearn.metrics import accuracy_score

print ("Accuracy : ", accuracy_score(y_test,y_pred))

from sklearn.ensemble import ExtraTreesClassifier

from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import ExtraTreeClassifier

X_train, X_test, y_train, y_test = train_test_split(X_test, y_test, random_state=0)
extra_tree = ExtraTreeClassifier(random_state=0)
extra_tree.fit(X_train, y_train)
cls = BaggingClassifier(extra_tree, random_state=0).fit(X_train, y_train)
cls.score(X_test,y_test)

import numpy as np
DistanceFromHome = int(input('Enter DistanceFromHome : '))
Gender = input('Enter the Gender of Employee : ')
MonthlyIncome = input('Enter the MonthlyIncome of the Employee : ')
JobRole = input('Enter the JobRole of the Employee : ')
PerformanceRating = input('Enter the PerformanceRating of the Employee : ')
TotalWorkingYears = input('Enter the TotalWorkingYears of the Employee : ')
YearsAtCompany = input('Enter the amount of Years employee wroked at the Company : ')
NumCompaniesWorked = input('Enter the NumCompaniesWorkedby the employee : ')

Data = np.array([[DistanceFromHome,Gender, MonthlyIncome, JobRole, PerformanceRating, TotalWorkingYears, YearsAtCompany,NumCompaniesWorked]])
prediction =forest.predict(Data)

print("---------------------------------Prediction----------------------------------")

if prediction == "0":
    print("Employee is Fit for this Company")
else:
    print("Employee need Attrition")